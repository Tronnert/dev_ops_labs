Выполнил: Стафеев Иван (K3221)

### Прогноз погоды - переменная теоретическая облачность!

Здесь написаны две рубежные работы по облачным технологиям и услугам в формате эссе. Приятного чтения!

# Рубежка №1. Вариант 5. Как гипервизор относится к виртуализации? Какие IT Tower можно виртуализовать?

#### Кто такие виртуализация и гипервизор?

Представим, что у вас есть сервер, просто какой-то сервер, выполняющий свои задачи - хранение БД и выполнение к ней запросов, физические расчеты для моделирования упругих волн, да будь он просто хранилищем с мемами про котиков. Перед вами встала задача расширения своего проекта, теперь нужно выполнять гораздо большее количество задач.

Что делать? Один из вариантов - купить еще несколько серверов, и пусть каждый грузится своими личными тасками. А что, если у вашего одного мощного сервера случится раздвоение личности (растроение, расчетверение, ....), и тогда на эти независимые "личности" мы повесим свою задачу? Звучит странно, но именно это представляет собой *виртуализация*.

**Виртуализация** - это процесс разделения физических ресурсов сервера (компьютера, устройства) между несколькими виртуальными независимыми, изолированными частями, могущих выполнять отделенные друг от друга процессы.

Чтобы виртуализация могла быть реализована на сервере, нужно *что-то*, что распределяло бы ограниченные ресурсы сервера между этими виртуальными частями (смело назовем их гостевыми операционными системами, а сам сервер - хостовой ОС). Этим чем-то является **гипервизор** - "программа", которая управляет физическими ресурсами сервера и распределяет эти ресурсы между несколькими операционными системами, позволяя запускать их одновременно.

Поясним кавычки. Есть два вида гипервизора - номер один и номер два. В чем их отличия?

1. **Гипервизор 1 типа** (aka гипервизор на "голом железе" - какое бесстыдство!). По сути это подобие операционной системы, только очень маленькой, которая ставится прямо на серверное железо. У нее есть признаки ОС в виде абстрактного набор ресурсов для программ и способности управлять памятью, процессорным временем, устройствами ввода-вывода. К таким гипервизорам можно отнести, например, *Xen*, *Hyper-V*, *KVM*.

2. **Гипервизор 2 типа**. Это уже больше программа, или программный слой, устанавливающийся поверх хостовой ОС и являющийся одним из ее процессов. В своих правах он более ограничен по сравнению с 1 типом, и управляет он только гостевыми ОС, а распределением ресурсов занимается хостовая ОС. Пример такого гипервизора - Oracle VM VirtualBox

В заключение про гипервизоры добавлю, что на самом деле гостевые ОС не обязательно полностью изолированы друг от друга. Они могут быть связаны посредством общего доступа к файлам или обмена данных в одном локальной сети

#### Делаем IT Tower виртуальным

Поскольку категории в IT Tower не являются строго определенными, здесь я буду пользоваться таксономией [TBM](https://higherlogicdownload.s3.amazonaws.com/TBMCOUNCIL/c15d372f-9951-46c8-9c3f-213c696401b6/UploadedImages/TBM_Taxonomy_V4_0.pdf). И тут мне хотелось сначала посмотреть на существующие 4 типа виртуализации, которые нам давали на информатике - виртуализацию приложений, представлений, сетевую и хранения - и сказать: "а-ага-а-а, вот уже ведь часть IT Tower виртуализовали", а потом понял, что это уже и не актуальная информация - нашел и 6 типов, и 7, и 3. Короче, проще сразу идти по всем "башенкам": 

1. **Data Center** - центр обработки данных - может быть виртуализирован на уровне рабочих нагрузок, а на уровне оборудования - нет, и делается это с помощью облачных решений. Например,  **Azure Stack** предоставляет инфраструктуру для управления облачными и локальными сервисами.

2. **Compute** - основная сфера виртуализации. Вычислительные сервера с помощью гипервизоров преобразуются в изолированные виртуальные машины, что повышает гибкость управления мощностями и снижает расходы на оборудование. Рабочий пример - **Azure Virtual Machines**, облачное решение для создания виртуалок.

3.  **Storage** подвергается виртуализации за счет объединения физических устройств в одну абстрагированную среду для хранения данных. Тут активно применяется концепция программно-определяемого хранилища (SDS), на основе которого работает, например **AWS S3**.

4. **Network** тоже можно виртуализовать, абстрагируя от физического уровня маршрутизацию, транспортировку и другие сетевые составляющие. Тут используются концепция виртуализации сетевых функций Network Function Virtualization (NFV), которую реализует, к примеру, **AWS Virtual Private Cloud (VPC)**, где можно виртуальное частное облако с изолированной сетью.

5. **Platform** без проблем виртуализируются, потому что платформенные сервисы PaaS чаще всего работают на виртуалках или контейнерах (что тоже является способом виртуализации). Пример - **AWS Amplify** - платформа для хостинга веб- и мобильных приложений.

6. **Output*** представляет ресурсы и услуги для конечных целей бизнеса, и виртуализация возможно тут только частичная. Все, что связано с обработкой и хранением данных, например, генерация отчетов, может быть виртуализовано (пример для этого - **Azure Power BI Embedded**), но конечные физические устройства (те же принтеры, на которых надо напечатать отчет) виртуализовать нельзя.

7. **End User** тоже могут быть виртуализированы только частично. Физические устройства виртуализовать нельзя, а вот пользовательские рабочие среды можно перенести в облако через Virtual Desktop Infrastructure (VDI) (это виртуализация представлений). Для такой виртуализации можно использовать **Azure Virtual Desktop** (название говорит само за себя)

8. **Application** поддаются виртуализации благодаря использованию контейнеризации и платформ виртуальных машин. Тут мы не говорим про ту же виртуализацию, про какую речь была в начале, а про немного другую - про контейнеры (Docker, например), для простоты назовем это более "легкой" виртуализацией, которая при этом не является в той же степени "изолированной", в какой находятся виртуальные машины. Пример - **Azure Kubernetes Service** - сервис для контейнеризации

9. **Delivery** может быть виртуализован частично, и дело опять в применяемых физических устройствах. Однако часть аспектов доставки приложений подвергаются виртуализации (или уже). Срди них: CI/CD (**AWS CodePipeline**), сама доставка данных (**Azure CDN**)

10. **Security & Compliance** виртуализируется частично. Виртуальные фаерволы, системы обнаружения и предотвращения вторжений (IDS/IPS), а также шифрование данных могут быть реализованы в виртуальной среде. Пример - **Azure Firewall**. Но физические элементы - аппаратные модули безопасности и другие - остаются физическими из-за их особенностей.

11. **IT Management** виртуализируется через облачные инструменты мониторинга и управления инфраструктурой. К примеру, **Azure Monitor** предоставляет услуги мониторинга, диагностики и анализа данных.

Подводя итог, можно сказать, что все составляющие IT Tower подвергаются виртуализации полностью или частично. По крайней мере, нет такой инфраструктуры, которую совсем нельзя было бы виртуализовать.  Проблема с полной виртуализацией состоит в необходимости физических устройств, которые как таковые виртуализовать нельзя и отказаться от которых тоже пока невозможно.

# Рубежка №2. Вариант 2. Для чего введен термин Infrastructure as a Code? Какие выгоды это несет с точки зрения автоматизации, безопасности? Предложите набор компонентов, которые нужно использовать при развертывании инфраструктуры как кода.

#### Что такое IaC?

Что делать, если в вашем проекте, в вашей инфраструктуре постоянно приходится писать множество конфигов, создавать SSH-подключения, обмениваться сертификатами и прочее и прочее? Делать все вручную - работает, однако от такой работы становится совсем грустно. Хочется это как-то *автоматизировать*. Чтобы не человек вручную прописывал все настройки, пути, запускал скрипты (а до этого писал их), а чтобы это было сделано автоматически, что сильно упростит процесс управления инфраструктурой, сделает его более согласованным, гибким и, что немаловажно, более дешевым.

Для такой автоматизации придумали **Infrastructure-as-Code** (IaC) - методологию, которая позволяет создавать, управлять и автоматизировать инфраструктуру, используя код.

 Целью IaC является стандартизация процессов управления инфраструктурой. IaC устраняет необходимость ручной настройки, превращая развертывание серверов, сетей и других ресурсов в рутинный повторяемый процесс (без негативной коннотации слова "рутинный"). Это особенно важно для гибридных и облачных систем, где без согласованного и отточенного процесса управления не обойтись.

Определяют три основных подхода к IaC:

1. **Императивный** - определяет последовательность конкретных команд, которые должны быть выполнены для достижения желаемой конфигурации.

2. **Декларативный** - определяет желаемый результат, а инструмент IaC сами разбираются, как его достичь.

3. **Гибридный**

#### Преимущества IaC

1. **Скорость и эффективность**. сценарии, скрипты, декларативные описания позволяют разворачивать инфраструктуру без (или почти без) участия человека, что делает этот процесс намного более быстрым. Также можно отметить **повторяемость** IaC - идентичные конфигурации могут быть развернуты в разных окружениях (для development'а и тестирования, например) - что тоже ускоряет, упрощает процесс и минимизирует количество ошибок.

2. **Согласование с DevOps.** Настройка инфраструктуры в виде кода может так же проходить контроль версий, автоматические тесты и CI/CD в целом, так же, как и код самого проекта.

3. **Масштабируемость**. Автоматические процессы позволяют быстро добавлять ресурсы при увеличении нагрузки или освобождать их при снижении.

4. **Контроль изменений**. Использование систем управления версиями (Git или другие), позволяет отслеживать любые изменения, легко восстанавливать предыдущие состояния и анализировать причины сбоев.

5. **Уменьшение количества человеческих ошибок**. Автоматизация потенциально уменьшает количество ошибок, которые могут быть допущены при развертке инфраструктуры, так как на каждом шаге без IaC действует человеческий фактор. Однако и в коде для развертки инфраструктуры могут быть ошибки, но их можно отслеживать с помощью Git, например.

6. **Встроенные политики безопасности**. IaC позволяет автоматически применять  определенные для проекта стандарты безопасности (ограничение доступа, обеспечение целостности, шифрование, сетевые правила и остальное), что тоже положительно сказывается на безопасности системы.

#### Недостатки IaC

1. **Зависимость от инструментов**. Приходится выбирать ряд инструментов для развертки, обучать им команду разработки, "зацикливаться" на этом наборе инструментов, поскольку они дают нужный результат. А если поддержка этих инструментов прекратится, будет крах - искать новые инструменты, переобучать команду, переписывать конфиги и скрипты, тратить очень много средств и тд.

2. **Сложное внедрение**. Внедрить IaC в своей проект может быть ничуть не проще, чем разработать еще один проект. Команда должна уметь в программирование и минимальный DevOps, чтобы создавать код для развертки инфраструктуры. Плюс само написание кода для развертки требует большого времени, а его еще и тестировать надо.

3. **Оверинжиниринг, излишняя автоматизация**. Если команда необдуманно следует IaC и, так сказать, подчиняется ему, она будет любую минимальную задачу пытаться автоматизировать, даже там, где проще руками написать конфиги. IaC - хороший инструмент, но переусердствовать тоже не стоит, иначе эта методология будет не упрощать рутинные задачи развертки, а усложнять
#### Компоненты IaC

1. **Языки описания инфраструктуры** (Terraform, AWS CloudFormation, Azure Resource Manager Templates)

**Terraform** -  инструмент для декларативного описания и управления инфраструктурой в разных облачных средах. Управление состоянием ресурсов также реализуется с помощью Terraform. Он синхронизирует текущую инфраструктуру с желаемой конфигурацией.

**AWS CloudFormation** и **Azure Resource Manager Templates** - инструменты для управления ресурсами в AWS и Azure соответственно, обеспечива.obt возможность интеграции с ними.

2. **Средства автоматизации** (Ansible, Chef, Puppet)

**Ansible** - автоматизация задач, использующая подход на основе YAML.

**Chef** - декларативные описания на языке Ruby.

**Puppet** - управление состоянием инфраструктуры через манифесты.

3. **Системы контроля версий**

Git - в пояснении не нуждается.

4. **CI/CD платформы** (Jenkins, GitHub Actions / GitLab CI)

Автоматизаций процесса развертки и интеграции. Эти инструменты обеспечивают автоматическое тестирование и развертку обновлений в инфраструктуре.

5. **Управление секретами, безопасное хранилище** (HashiCorp Vault, AWS Secrets Manager, Azure Key Vault)

HashiCorp Vault - безопасное хранение конфиденциальной информации и управление доступом к ней

AWS Secrets Manager, Azure Key Vault - интеграция с облачными сервисами для надежного управления секретами.

6. **Мониторинг, логирование** (Grafana, Prometheus, ELK Stack)

Grafana и Prometheus - сбор метрик и их визуализаций

ELK Stack - централизованное логирование, анализ и поиск по логам
